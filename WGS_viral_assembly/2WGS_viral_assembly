#!/bin/bash
###############################################################
## whole Genome Sequence Assembly pipelines for viral genome ##
###############################################################

#NOTE: This assignment is built on the already published raw data from the MPOX outbreak in Kamituga, South Kivu
# You may be able to access the publication by following the link: https://www.eurosurveillance.org/content/10.2807/1560-7917.ES.2024.29.11.2400106 

#Step 0: Let us get the raw data to use 

#First we will create the necessary working directory for rw data.

cd $WGS_HOME
echo $WGS_DATA_DIR
mkdir -p $WGS_DATA_DIR
mkdir -p $WGS_REFS_DIR

#Let us change the directory (cd) and go to the created data directory for raw data
cd $WGS_DATA_DIR

#Now check which directory you are in. The terminal should show that you are in the data directory 
pwd

#Step 1: Download raw data and the reference genome in their respective directories
#########################################################################################

#Let us change the directory (cd) and go to the created data directory for raw data
cd $WGS_DATA_DIR

#Make sure you are in the right directory and download the raw data (FASTQ files)

cd $WGS_HOME/data/

#Then we can start downloading the data... NOTE: you can download only one of the 3 provided options and carry on till the end
#The raw data is hosted at the EMBL institute, and you can download it to your local linux system using 'wget' function 

wget ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR126/001/ERR12670101/ERR12670101.fastq.gz
wget ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR126/004/ERR12670104/ERR12670104.fastq.gz
wget ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR126/005/ERR12670105/ERR12670105.fastq.gz

# Unzip the file to be able to inspect it 
gunzip *.fastq.gz

ls #check how many files you have in your folder 

#QUESTION 1: inspect the file and describe which type of file it is and its relatively important characteristics. 
#            How many reads do we have in that file?
#            You can use the command bellow to count how many reads are there: 

grep -o '@ERR12670' ERR12670104.fastq | wc -l    #How many reads are they? 

#Rename your FASTQ file to easily follow the next steps...
cp ERR12670104.fastq all_reads.fastq

#Let us change the directory (cd) and go to the created directory for reference sequence

cd $WGS_REFS_DIR

#use the 'wget' function to download the reference format 

wget https://www.ebi.ac.uk/ena/browser/api/fasta/JX878425.1?download=true > mpox_ref.fasta



#Step 2: Quality Control (QC) check using NanoPlot
##################################################

#Create the directory to store quality data
cd $WGS_HOME
echo $WGS_DATA_TRIM_DIR
mkdir -p $WGS_DATA_TRIM_DIR

#Run the command below ensuring that the right <FILE NAME> is provided 

nanoplot --fastq all_reads.fastq -o $WGS_DATA_TRIM_DIR

#Go to the $WGS_DATA_TRIM_DIR directory and open the generated files to understand the quality status 

#Step 3: Data filtering based on quality score Q() using fastp
##############################################################

fastp -i all_reads.fastq -o $WGS_DATA_TRIM_DIR/all_reads_QC.fastq -q 9 -Q

#QUESTION 3: Please report the values below, from the data you find: 
#total reads: ____________
#total bases: _____________
#Q20 bases: ____________%____
#Q30 bases: ____________%______

#Read1 after filtering:
#total reads:_________
#total bases: __________
#Q20 bases: _________%_________
#Q30 bases: __________%________

#Filtering result:_____________
#reads passed filter: _________________
#reads failed due to low quality:________
#reads failed due to too many N: __________
#reads failed due to too short:_______________
#reads with adapter trimmed: ____________
#bases trimmed due to adapters:_______________

#Step 4: Trim adapters from the first and the last end
######################################################

#Check if the cutadapt tool is installed and if not install using the command bellow: 

sudo apt install cutadapt

#Trim adapters from the first end of the reads

cutadapt -u 30 -o $WGS_DATA_TRIM_DIR/all_reads_QC1.fastq $WGS_DATA_TRIM_DIR/all_reads_QC.fastq

# Trim adapters from the other end of the reads

cutadapt -u -30 -o $WGS_DATA_TRIM_DIR/all_reads_QC2.fastq $WGS_DATA_TRIM_DIR/all_reads_QC1.fastq

QUESTION 4: Compare Total basepairs processed in both 'cutadapt' steps. Are they the same or different? Why? 


#Step 5: Align reads to the reference genome using minimap2 and generate SAM file
#################################################################################

echo $WGS_HOME

# Align reads to the reference genome by providing the right PATH to your data and the reference and generate SAM file
minimap2 -Y -t 12 -x map-ont -a /Users/JeanPierre/Documents/Bioinformatics/barcode25/SARS_Cov2_refs/GCA_009858895.3.fasta all_reads_QC2.fastq > all_reads.sam

#Step 6: Sort the SAM file

# Sort the SAM file
samtools sort -O SAM -o all_reads_sorted.sam all_reads.sam

#Step 7: Convert SAM to BAM and sort

# Convert SAM to BAM and sort the BAM file
samtools view -bS all_reads_sorted.sam | samtools sort -@ 16 -o all_reads.bam

#Step 8: Index the BAM file

# Index the BAM file
samtools index all_reads.bam

#Step 9: Create a depth profile

# Create a depth profile of the aligned reads
samtools mpileup -a -A -Q 0 -d 0 -f /Users/JeanPierre/Documents/Bioinformatics/NRL_SARS_CoV2/SARS_Cov2_refs/GCA_009858895.3.fasta all_reads.bam | awk '{print $2","$3","$4}' > all_reads.depth

#Step 10: Variant calling

# Call variants using bcftools
bcftools mpileup -f /Users/JeanPierre/Documents/Bioinformatics/barcode25/SARS_Cov2_refs/GCA_009858895.3.fasta all_reads.bam | bcftools call -mv -Oz -o all_reads.vcf.gz

#Step 11: Filter the VCF file

# Filter the VCF file using bcftools
bcftools filter -i 'DP>20 && AF>0.1' all_reads.vcf.gz -Oz -o all_reads_filtered.vcf.gz

#Step 12: Create a consensus sequence


# Index the reference genome
samtools faidx /Users/JeanPierre/Documents/Bioinformatics/NRL_SARS_CoV2/barcode25/SARS_Cov2_refs/GCA_009858895.3.fasta

# Generate consensus sequence with bcftools consensus
bcftools consensus -f /Users/JeanPierre/Documents/Bioinformatics/barcode25/SARS_Cov2_refs/GCA_009858895.3.fasta all_reads_filtered.vcf.gz > all_reads_consensus_temp.fasta

# Incorporate depth profile into the consensus sequence
awk -F, -v depth_file=all_reads.depth 'BEGIN {
  while ((getline < depth_file) > 0) {
    depth[$1] = $3
  }
}
{
  if (/^>/) {
    print $0
  } else {
    seq = $0
    for (i = 1; i <= length(seq); i++) {
      if (depth[i] < 20) {
        seq = substr(seq, 1, i-1) "N" substr(seq, i+1)
      }
    }
    print seq
  }
}' all_reads_consensus_temp.fasta > all_reads_consensus.fasta
